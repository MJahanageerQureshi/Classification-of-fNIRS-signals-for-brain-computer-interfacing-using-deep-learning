{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9h4t2_zd7uX1"
   },
   "source": [
    "# fNIRS signal Classification using Deep learning\n",
    "---\n",
    "## Functional Near-Infrared Spectroscopy (fNIR or fNIRS), is the use of near-infrared spectroscopy (NIRS) for the purpose of functional neuroimaging. Using fNIR, brain activity is measured through hemodynamic responses associated with neuron behaviour. fNIRS signals have been successfully implemented as a control signal for BCI systems.Keeping that in mind this project intends to improve the detection accuracy of such BCI systems using Deep Neural Networks.\n",
    "### The problem that this project aims to tackle is to diffrentiate between a rest and active state of a human using fNIRS signals of the person in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlBWvl9sAKo4"
   },
   "source": [
    "# Loading and preprocessing of data \n",
    "---\n",
    "## We shall first begin by loading the datasets provided. The dataset has been filtered and preprocessed before hand making further classifications easier. It is composed into two parts Oxy and Deoxy. This refers to the different blood channels that were used to extract the fNIRS signals. We will standardize the data making its Mean 0 and its Variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sZqglmNFHnmw"
   },
   "outputs": [],
   "source": [
    "# import library and data\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn import preprocessing\n",
    "\n",
    "fNIRS_data_oxy = sio.loadmat('data_oxy.mat')\n",
    "# preproccesing data for zero mean and 1 variance\n",
    "data_oxy = preprocessing.scale(np.array(fNIRS_data_oxy['data']))\n",
    "labels_oxy = np.array(fNIRS_data_oxy['labels'])\n",
    "\n",
    "fNIRS_data_deoxy = sio.loadmat('data_deoxy.mat')\n",
    "data_deoxy = preprocessing.scale(np.array(fNIRS_data_deoxy['data']))\n",
    "labels_deoxy = np.array(fNIRS_data_deoxy['labels'])\n",
    "\n",
    "data_hybrid = np.concatenate((data_oxy, data_deoxy),axis = 1)\n",
    "labels_hybrid = labels_oxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxHu-ddlCkZQ"
   },
   "source": [
    "# Defining Deep Neural Network Models\n",
    "---\n",
    "## For the task at hand 3 different models will be created firstly for the Oxy dataset secondly for the Deoxy dataset and thirdly a combination of the two. \n",
    "## For some experimentation we also added a graph model that takes data from both the Oxy and Deoxy datasets passes them through the some layers and then tries to classify using the new embeddings made during the forward pass.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "csoH45uDHnm3",
    "outputId": "c95b924a-5e37-4394-b7a2-4c720e4e0670"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def oxymdl():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def deoxymdl():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def hbrdmdl():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def hbrdgrfmdl():\n",
    "    in_ox = Input(shape=(16,))\n",
    "    in_deox = Input(shape=(16,))\n",
    "    \n",
    "    ox = Dense(100, activation='relu')(in_ox)\n",
    "    ox = BatchNormalization()(ox)\n",
    "    deox = Dense(100, activation='relu')(in_deox)\n",
    "    deox = BatchNormalization()(deox)\n",
    "    ox = Dense(100, activation='relu')(ox)\n",
    "    ox = BatchNormalization()(ox)\n",
    "    deox = Dense(100, activation='relu')(deox)\n",
    "    deox = BatchNormalization()(deox)\n",
    "    ox = Dense(100, activation='relu')(ox)\n",
    "    ox = BatchNormalization()(ox)\n",
    "    deox = Dense(100, activation='relu')(deox)\n",
    "    deox = BatchNormalization()(deox)\n",
    "    ox = Dense(100, activation='relu')(ox)\n",
    "    ox = BatchNormalization()(ox)\n",
    "    deox = Dense(100, activation='relu')(deox)\n",
    "    deox = BatchNormalization()(deox)\n",
    "    ox = Dense(100, activation='relu')(ox)\n",
    "    ox = BatchNormalization()(ox)\n",
    "    deox = Dense(100, activation='relu')(deox)\n",
    "    deox = BatchNormalization()(deox)\n",
    "    x = concatenate([ox, deox])\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.3)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[in_ox, in_deox], outputs=[out])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgcOLjtnEDD0"
   },
   "source": [
    "# Oxy model\n",
    "---\n",
    "## Here we check the accuracy of the Oxy model using cross validation. 5 folds are created and the model is trained and tested upon them\n",
    "## The mean accuracy for the Oxy model is 99.40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "K2u54Ry8Hnm8",
    "outputId": "1e80d447-c5f8-4976-a258-1fba6c654655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99193548  0.99193548  0.99731183  0.99641577  0.99282511]\n",
      "0.994084735683\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "model = KerasClassifier(build_fn=oxymdl, epochs=20, batch_size=100, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "results = cross_val_score(model, data_oxy, labels_oxy, cv=kfold)\n",
    "print(results)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDN6pcoYE_qV"
   },
   "source": [
    "# Deoxy model\n",
    "---\n",
    "## Here we check the accuracy of the Deoxy model using cross validation. 5 folds are created and the model is trained and tested upon them\n",
    "## The mean accuracy for the Deoxy model is 99.39%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "6C_u0SfLHnnC",
    "outputId": "6cb160d6-f26d-44e0-f915-d2e848c7b99a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99193548  0.99193548  0.99731183  0.99551971  0.99282511]\n",
      "0.993905524214\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=deoxymdl, epochs=20, batch_size=100, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "results = cross_val_score(model, data_deoxy, labels_deoxy, cv=kfold)\n",
    "print(results)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htgjTHZHF4_9"
   },
   "source": [
    "# Hybrid model\n",
    "---\n",
    "## Here we check the accuracy of the Hybrid model using cross validation. 5 folds are created and the model is trained and tested upon them\n",
    "## The mean accuracy for the Hybrid model is 99.44%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "LXiqlNRSHnnK",
    "outputId": "74bb14f1-e1fc-4389-cced-ce4404d2cb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99283154  0.99193548  0.99731183  0.99641577  0.99372197]\n",
      "0.99444331935\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=hbrdmdl, epochs=20, batch_size=100, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "results = cross_val_score(model, data_hybrid, labels_hybrid, cv=kfold)\n",
    "print(results)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOvXcsdQFTaE"
   },
   "source": [
    "# Hybrid Graph model\n",
    "---\n",
    "## Here we train and check the accuracy of the Hybrid Graph model. The model is trained upon 85% and tested on 15% of the dataset\n",
    "## The test accuracy for the Oxy model is 99.28%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "NPJrFkV1HnnT",
    "outputId": "9c6c9bae-1061-42cd-fa8e-ba443391996e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4030 samples, validate on 712 samples\n",
      "Epoch 1/20\n",
      "4030/4030 [==============================] - 2s 542us/step - loss: 0.2034 - acc: 0.9323 - val_loss: 0.4289 - val_acc: 0.9719\n",
      "Epoch 2/20\n",
      "4030/4030 [==============================] - 2s 407us/step - loss: 0.0723 - acc: 0.9886 - val_loss: 0.1934 - val_acc: 0.9972\n",
      "Epoch 3/20\n",
      "4030/4030 [==============================] - 2s 397us/step - loss: 0.0568 - acc: 0.9918 - val_loss: 0.0844 - val_acc: 0.9944\n",
      "Epoch 4/20\n",
      "4030/4030 [==============================] - 2s 430us/step - loss: 0.0479 - acc: 0.9918 - val_loss: 0.0409 - val_acc: 0.9972\n",
      "Epoch 5/20\n",
      "4030/4030 [==============================] - 2s 411us/step - loss: 0.0511 - acc: 0.9893 - val_loss: 0.0306 - val_acc: 0.9972\n",
      "Epoch 6/20\n",
      "4030/4030 [==============================] - 2s 412us/step - loss: 0.0449 - acc: 0.9928 - val_loss: 0.0232 - val_acc: 0.9972\n",
      "Epoch 7/20\n",
      "4030/4030 [==============================] - 2s 413us/step - loss: 0.0409 - acc: 0.9933 - val_loss: 0.0208 - val_acc: 0.9972\n",
      "Epoch 8/20\n",
      "4030/4030 [==============================] - 2s 413us/step - loss: 0.0397 - acc: 0.9933 - val_loss: 0.0186 - val_acc: 0.9972\n",
      "Epoch 9/20\n",
      "4030/4030 [==============================] - 2s 410us/step - loss: 0.0354 - acc: 0.9938 - val_loss: 0.0225 - val_acc: 0.9972\n",
      "Epoch 10/20\n",
      "4030/4030 [==============================] - 2s 412us/step - loss: 0.0358 - acc: 0.9940 - val_loss: 0.0190 - val_acc: 0.9972\n",
      "Epoch 11/20\n",
      "4030/4030 [==============================] - 2s 405us/step - loss: 0.0389 - acc: 0.9923 - val_loss: 0.0203 - val_acc: 0.9972\n",
      "Epoch 12/20\n",
      "4030/4030 [==============================] - 2s 414us/step - loss: 0.0320 - acc: 0.9938 - val_loss: 0.0206 - val_acc: 0.9972\n",
      "Epoch 13/20\n",
      "4030/4030 [==============================] - 2s 430us/step - loss: 0.0330 - acc: 0.9933 - val_loss: 0.0206 - val_acc: 0.9972\n",
      "Epoch 14/20\n",
      "4030/4030 [==============================] - 2s 425us/step - loss: 0.0409 - acc: 0.9916 - val_loss: 0.0236 - val_acc: 0.9972\n",
      "Epoch 15/20\n",
      "4030/4030 [==============================] - 2s 414us/step - loss: 0.0313 - acc: 0.9935 - val_loss: 0.0352 - val_acc: 0.9958\n",
      "Epoch 16/20\n",
      "4030/4030 [==============================] - 2s 413us/step - loss: 0.0352 - acc: 0.9931 - val_loss: 0.0198 - val_acc: 0.9972\n",
      "Epoch 17/20\n",
      "4030/4030 [==============================] - 2s 409us/step - loss: 0.0322 - acc: 0.9935 - val_loss: 0.0204 - val_acc: 0.9972\n",
      "Epoch 18/20\n",
      "4030/4030 [==============================] - 2s 401us/step - loss: 0.0302 - acc: 0.9931 - val_loss: 0.0215 - val_acc: 0.9972\n",
      "Epoch 19/20\n",
      "4030/4030 [==============================] - 2s 422us/step - loss: 0.0294 - acc: 0.9928 - val_loss: 0.0329 - val_acc: 0.9958\n",
      "Epoch 20/20\n",
      "4030/4030 [==============================] - 2s 431us/step - loss: 0.0287 - acc: 0.9948 - val_loss: 0.0269 - val_acc: 0.9958\n",
      "837/837 [==============================] - 0s 216us/step\n",
      "\n",
      "acc: 99.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "graph_model = hbrdgrfmdl()\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(data_oxy, labels_oxy, random_state = 42, test_size = .15)\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(data_deoxy, labels_deoxy, random_state = 42, test_size = .15)\n",
    "\n",
    "graph_model.fit([X1_train, X2_train], [Y1_train], epochs=20, batch_size=100, validation_split = .15, verbose = 1)\n",
    "scores = graph_model.evaluate([X1_test, X2_test], [Y1_test])\n",
    "print(\"\\n%s: %.2f%%\" % (graph_model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "fNIRS_K-fold.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
